{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch as tc\n",
    "from scipy.signal import fftconvolve\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "tc.random.manual_seed(0)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from skimage.restoration import wiener\n",
    "device = tc.device('cuda:0' if tc.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 準備するフィルタのサイズを5x5に固定\n",
    "X, Y = np.meshgrid(np.arange(-2, 3, 1, dtype=np.float32), np.arange(-2, 3, 1, dtype=np.float32))\n",
    "gauss_filters = []\n",
    "std = 0.8\n",
    "f = np.vectorize(\n",
    "    lambda x, y: multivariate_normal([0.0, 0.0], np.diag([std]*2)).pdf([x, y])\n",
    ")\n",
    "kernel = f(X, Y)\n",
    "kernel = kernel / kernel.sum()\n",
    "kernel = kernel.astype(np.float32)\n",
    "gauss1 = kernel\n",
    "\n",
    "tc.random.manual_seed(0)\n",
    "kernel = tc.rand((5, 5))\n",
    "kernel = kernel / kernel.sum()\n",
    "random1 = kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx: 0: gauss, 1: random\n",
    "blur_kernels = [gauss1, random1]\n",
    "\n",
    "class BluredMNIST(MNIST):\n",
    "    def __getitem__(self, index):\n",
    "        '''blur img and change target'''\n",
    "        img, target = super().__getitem__(index)\n",
    "        blur_index = tc.randint(0, 2, ())\n",
    "        blur_kernel = blur_kernels[blur_index]\n",
    "        img = fftconvolve(img[0], blur_kernel, mode='same')\n",
    "        return img[np.newaxis, :], blur_index\n",
    "        \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = BluredMNIST(root='data/', train=True, download=True, transform=transform)\n",
    "testset = BluredMNIST(root='data/', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=32)\n",
    "testloader = DataLoader(testset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        lows, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(lows)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('%d, %5d loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with tc.no_grad():\n",
    "    for img, label in testloader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        z = tc.argmax(net(img).squeeze(0))\n",
    "        y_true.append(label.item())\n",
    "        y_pred.append(z.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.save(net.state_dict(), './feature_extraction.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
