{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.stats import multivariate_normal\n",
    "from skimage import restoration\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import train_agent as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "seed = 0\n",
    "test_blur = 'random'\n",
    "#test_blur = 'random'\n",
    "num_blur = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels\n",
    "std = 3.0\n",
    "f = np.vectorize(lambda x, y: multivariate_normal([0.0, 0.0], np.diag([std]*2)).pdf([x, y]))\n",
    "X, Y = np.meshgrid(np.arange(-2, 3, 1, dtype=np.float32), np.arange(-2, 3, 1, dtype=np.float32))\n",
    "kernel1 = f(X, Y)\n",
    "kernel1 = kernel1 / kernel1.sum()\n",
    "np.random.seed(0)\n",
    "kernel2 = np.random.rand(*kernel1.shape)\n",
    "kernel2 = kernel2 / kernel2.sum()\n",
    "\n",
    "# filters\n",
    "filt = []\n",
    "filt.append(lambda x: x)\n",
    "filt.append(lambda x: np.maximum(0, fftconvolve(x, kernel1, mode='same')))\n",
    "filt.append(lambda x: np.maximum(0, fftconvolve(x, kernel2, mode='same')))\n",
    "filt.append(lambda x: np.maximum(0, restoration.wiener(x, kernel1, 1e-2)))\n",
    "filt.append(lambda x: np.maximum(0, restoration.wiener(x, kernel2, 1e-2)))\n",
    "filt_names = ['None', 'Blur1', 'Blur2', 'Wiener1', 'Wiener2']\n",
    "\n",
    "# images\n",
    "# data = datasets.MNIST(root='./data', train=True, download=True)\n",
    "data = datasets.MNIST(root='./data', train=False, download=True)\n",
    "np.random.seed(seed)\n",
    "# idx = np.random.choice(data.data.shape[0], 2000)\n",
    "# imgs = data.data[idx].numpy() / 255\n",
    "imgs = data.data.numpy() / 255\n",
    "if test_blur == 'gauss':\n",
    "    blurred_imgs = np.stack(list(map(lambda x: ta.blur(x, kernel1, c=num_blur), imgs)), axis=0)\n",
    "    filt_inv = filt[3]\n",
    "elif test_blur == 'random':\n",
    "    blurred_imgs = np.stack(list(map(lambda x: ta.blur(x, kernel2, c=num_blur), imgs)), axis=0)\n",
    "    filt_inv = filt[4]\n",
    "imgs = torch.from_numpy(imgs).to(torch.float)\n",
    "blurred_imgs = torch.from_numpy(blurred_imgs).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 加藤テストデータを読み込む。\n",
    "# これをblurred_imgs, imgsと照らし合わせる\n",
    "context = np.load('data/GR3.0/test/random/c3_dataset.npz')\n",
    "Dy = context['test_dataset']\n",
    "Dx = context['original_dataset']\n",
    "\n",
    "print(np.allclose(Dy, blurred_imgs))\n",
    "print(np.allclose(Dx, imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(imgs, blurred_imgs, i, channel=1):\n",
    "    y, x = imgs[[i]], blurred_imgs[[i]]\n",
    "    if channel == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "    elif channel == 2:\n",
    "        x = torch.cat([x, x], dim=0).unsqueeze(0)\n",
    "    return (x, y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046024732291698456"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE of initial images\n",
    "torch.mean((blurred_imgs - imgs)**2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe922cf7dc344f039238b98f91927748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.01962356203519739 0.00718379020428755\n"
     ]
    }
   ],
   "source": [
    "# MSE of fixed corresponding filter\n",
    "with torch.no_grad():\n",
    "    err = []\n",
    "    for i in tqdm(range(imgs.shape[0])):\n",
    "        s = get_img(imgs, blurred_imgs, i, channel=2)\n",
    "        for j in range(5):\n",
    "            x, y = s\n",
    "            if j < num_blur:\n",
    "                x[0, 0, :, :] = torch.tensor(filt_inv(x[0, 0, :, :].numpy()))\n",
    "                s_next = (x, y)\n",
    "            else:\n",
    "                s_next = s\n",
    "            r = ta.reward(s, s_next, 0)\n",
    "            s = s_next\n",
    "        err.append(torch.mean((s[0][0, 0] - s[1][0, 0])**2).item())\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49105eeddbd44d588af6a23985b64b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.021505156240612267 0.008252542286371371\n"
     ]
    }
   ],
   "source": [
    "# MSE of agent\n",
    "Qnet = ta.MnistNet(c=2, m=[20, 20, len(filt)])\n",
    "Qnet.load_state_dict(torch.load('./Qnet020000.pth', map_location=torch.device('cpu')))\n",
    "Qnet = Qnet.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    err = []\n",
    "    count = np.zeros((len(filt), 5))\n",
    "    for i in tqdm(range(imgs.shape[0])):\n",
    "        s = get_img(imgs, blurred_imgs, i, channel=2)\n",
    "        for j in range(5):\n",
    "            x, y = s\n",
    "            q = Qnet(x.to(device))\n",
    "            q = q[0].to('cpu').numpy()\n",
    "            a = np.argmax(q)\n",
    "            s_next = ta.next_state(s, a, filt, channel=2)\n",
    "            r = ta.reward(s, s_next, a)\n",
    "            s = s_next\n",
    "            count[a, j] = count[a, j] + 1\n",
    "        err.append(torch.mean((s[0][0, 0] - s[1][0, 0])**2).item())\n",
    "print(np.mean(err), np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 2))\n",
    "for j in range(5):\n",
    "    plt.subplot(1, 5, j+1)\n",
    "    plt.bar(range(len(filt)), count[:, j])\n",
    "    plt.title('step%d' % (j+1,))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(\n",
    "    os.path.dirname(os.path.abspath('.'))\n",
    ")\n",
    "from src import QNet, Agent, agent_metrics, show_reward, settings\n",
    "### path load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a624a5e43c4746579c79956aa41734d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.021505096565838905 0.00825363370084882\n",
      "<class 'torch.Tensor'>\n",
      "(10000, 28, 28)\n",
      "agent (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE of agent\n",
    "Qnet = ta.MnistNet(c=2, m=[20, 20, len(filt)])\n",
    "Qnet.load_state_dict(torch.load('./Qnet020000.pth', map_location=torch.device('cpu')))\n",
    "# Qnet = Qnet.to(device)\n",
    "\n",
    "\n",
    "def satohara_metric(Qnet, blurred_imgs, imgs):\n",
    "    with torch.no_grad():\n",
    "        err = []\n",
    "        count = np.zeros((len(filt), 5))\n",
    "        res = []\n",
    "        for i in tqdm(range(imgs.shape[0])):\n",
    "            s = get_img(imgs, blurred_imgs, i, channel=2)\n",
    "            for j in range(5):\n",
    "                x, y = s\n",
    "                q = Qnet(x)\n",
    "                q = q[0].to('cpu').numpy()\n",
    "                a = np.argmax(q)\n",
    "                s_next = ta.next_state(s, a, filt, channel=2)\n",
    "                s = s_next\n",
    "                count[a, j] = count[a, j] + 1\n",
    "            err.append(torch.mean((s[0][0, 0] - s[1][0, 0])**2).item())\n",
    "            res.append(s[0][0, 0].numpy())\n",
    "    print(np.mean(err), np.std(err))\n",
    "    print(type(s[0][0, 0]))\n",
    "    return np.array(res)\n",
    "\n",
    "def agent_output(Qnet, Dy, Dx, filt):\n",
    "    agent = Agent(Qnet, filt, 2)\n",
    "    out = []\n",
    "    for n in range(Dy.shape[0]):\n",
    "        yn = Dy[n]\n",
    "        yn, _ = agent(yn)\n",
    "        out.append(yn.numpy())\n",
    "    return np.array(out)\n",
    "\n",
    "# 3種類のフィルタ\n",
    "context = np.load('data/GR3.0/test/random/c3_dataset.npz')\n",
    "Dy = torch.from_numpy(context['test_dataset']).to(torch.float)\n",
    "Dx = torch.from_numpy(context['original_dataset']).to(torch.float)\n",
    "\n",
    "# a = 3\n",
    "# i = 4\n",
    "# s = get_img(Dx, Dy, i, channel=2)\n",
    "# next_state = ta.next_state(s, a, filt, channel=2)\n",
    "# print(next_state[0].shape)\n",
    "\n",
    "out_satohara = satohara_metric(Qnet, Dy, Dx)\n",
    "print(out_satohara.shape)\n",
    "# kato\n",
    "\n",
    "def agent_next(s, a, Qnet, actions):\n",
    "    z, y = s.squeeze(0)\n",
    "    z = z.cpu().numpy()\n",
    "    z_next = actions[a](z)\n",
    "    z_next = torch.from_numpy(z_next).to(torch.float)\n",
    "    return torch.stack([z_next, y]).unsqueeze(0)\n",
    "\n",
    "# out = agent_next(s[0], a, Qnet, filt)\n",
    "# print(out.shape)\n",
    "# print(np.allclose(out.numpy(), next_state[0].numpy()))\n",
    "\n",
    "out_kato = agent_output(Qnet, Dy, Dx, filt)\n",
    "print('agent', out_kato.shape)\n",
    "np.allclose(out_kato, out_satohara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:19<00:00, 125.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.021505096565838905"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_metrics(Dy, Dx, Qnet, filt, channel=2)\n",
    "result[:, -1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "73441ad3b61dff827bc7e7300aef9bd78709d897ff54f13abd5d5963595f26db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
